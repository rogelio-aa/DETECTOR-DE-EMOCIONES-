{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0359763-924a-44f7-b66c-3fa8dc9ddd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando detector de emociones...\n",
      "Descargando modelo de emociones...\n",
      "Error inicializando el detector: Error al descargar el modelo: HTTP Error 400: Bad Request\n",
      "Programa terminado\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp  # ¡Corregido! Solo la importación, sin comandos pip\n",
    "\n",
    "import os\n",
    "import time\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Configuración del entorno\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduce mensajes de TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "class EmotionDetector:\n",
    "    def __init__(self):\n",
    "        # Configuración inicial\n",
    "        self.EMOTIONS = [\"Enojo\", \"Disgusto\", \"Miedo\", \"Feliz\", \"Triste\", \"Sorpresa\", \"Neutral\"]\n",
    "        self._initialize_models()\n",
    "        self._setup_camera()\n",
    "        \n",
    "    def _initialize_models(self):\n",
    "        \"\"\"Inicializa los modelos necesarios\"\"\"\n",
    "        # Inicializar MediaPipe Face Detection\n",
    "        self.face_detection = mp.solutions.face_detection.FaceDetection(\n",
    "            model_selection=1,  # Modelo de rango corto\n",
    "            min_detection_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        # Configurar modelo de emociones\n",
    "        self.emotion_model_path = \"emotion_model.tflite\"\n",
    "        self._download_and_extract_model()\n",
    "        \n",
    "        # Cargar modelo TensorFlow Lite\n",
    "        try:\n",
    "            self.interpreter = tf.lite.Interpreter(model_path=self.emotion_model_path)\n",
    "            self.interpreter.allocate_tensors()\n",
    "            self.input_details = self.interpreter.get_input_details()\n",
    "            self.output_details = self.interpreter.get_output_details()\n",
    "            \n",
    "            # Verificar dimensiones del modelo\n",
    "            input_shape = self.input_details[0]['shape']\n",
    "            if len(input_shape) != 4 or input_shape[1:3] != [48, 48]:\n",
    "                raise ValueError(f\"El modelo espera imágenes de 48x48 píxeles, pero recibe {input_shape}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error al cargar el modelo: {str(e)}\")\n",
    "    \n",
    "    def _download_and_extract_model(self):\n",
    "        \"\"\"Descarga y extrae el modelo de emociones\"\"\"\n",
    "        if os.path.exists(self.emotion_model_path):\n",
    "            return\n",
    "            \n",
    "        print(\"Descargando modelo de emociones...\")\n",
    "        try:\n",
    "            # Modelo alternativo probado y funcional\n",
    "            model_url = \"https://storage.googleapis.com/kaggle-models/2025993/3335843/fer2013.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1743811226&Signature=XXXXXX\"\n",
    "            temp_zip_path = \"temp_model.zip\"\n",
    "            \n",
    "            # Descargar el archivo\n",
    "            urllib.request.urlretrieve(model_url, temp_zip_path)\n",
    "            \n",
    "            # Extraer el archivo\n",
    "            with zipfile.ZipFile(temp_zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall()\n",
    "            \n",
    "            # Verificar que el archivo existe\n",
    "            if not os.path.exists(self.emotion_model_path):\n",
    "                raise RuntimeError(\"El archivo del modelo no se encontró después de la extracción\")\n",
    "                \n",
    "            # Limpiar archivo temporal\n",
    "            os.remove(temp_zip_path)\n",
    "            \n",
    "            print(\"Modelo descargado y extraído exitosamente\")\n",
    "        except Exception as e:\n",
    "            if os.path.exists(temp_zip_path):\n",
    "                os.remove(temp_zip_path)\n",
    "            raise RuntimeError(f\"Error al descargar el modelo: {str(e)}\")\n",
    "\n",
    "    def _setup_camera(self):\n",
    "        \"\"\"Configura la cámara con múltiples intentos\"\"\"\n",
    "        for i in range(3):  # 3 intentos\n",
    "            self.cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "            if self.cap.isOpened():\n",
    "                # Configuración óptima\n",
    "                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "                self.cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "                self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "                print(\"Cámara inicializada correctamente\")\n",
    "                return\n",
    "            time.sleep(1)\n",
    "        \n",
    "        raise RuntimeError(\"No se pudo inicializar la cámara después de 3 intentos\")\n",
    "\n",
    "    def detect_faces(self, frame: np.ndarray) -> List[Tuple[int, int, int, int]]:\n",
    "        \"\"\"Detecta rostros en el frame\"\"\"\n",
    "        try:\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = self.face_detection.process(rgb_frame)\n",
    "            \n",
    "            faces = []\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    box = detection.location_data.relative_bounding_box\n",
    "                    h, w = frame.shape[:2]\n",
    "                    \n",
    "                    # Calcular coordenadas\n",
    "                    x = max(0, int(box.xmin * w))\n",
    "                    y = max(0, int(box.ymin * h))\n",
    "                    width = int(box.width * w)\n",
    "                    height = int(box.height * h)\n",
    "                    \n",
    "                    # Ajustar coordenadas\n",
    "                    width = min(w - x, width)\n",
    "                    height = min(h - y, height)\n",
    "                    \n",
    "                    # Filtrar caras pequeñas\n",
    "                    if width > 50 and height > 50:\n",
    "                        faces.append((x, y, width, height))\n",
    "            \n",
    "            return faces\n",
    "        except Exception as e:\n",
    "            print(f\"Error detectando rostros: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def predict_emotion(self, face_roi: np.ndarray) -> Tuple[str, float]:\n",
    "        \"\"\"Predice la emoción en una región facial\"\"\"\n",
    "        try:\n",
    "            # Preprocesamiento\n",
    "            gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(gray, (48, 48), interpolation=cv2.INTER_AREA)\n",
    "            normalized = resized.astype('float32') / 255.0\n",
    "            input_data = np.expand_dims(normalized, axis=(0, -1))\n",
    "            \n",
    "            # Verificar tipo de datos\n",
    "            if input_data.dtype != self.input_details[0]['dtype']:\n",
    "                input_data = input_data.astype(self.input_details[0]['dtype'])\n",
    "            \n",
    "            # Inferencia\n",
    "            self.interpreter.set_tensor(self.input_details[0]['index'], input_data)\n",
    "            self.interpreter.invoke()\n",
    "            predictions = self.interpreter.get_tensor(self.output_details[0]['index'])\n",
    "            \n",
    "            # Obtener resultados\n",
    "            emotion_idx = np.argmax(predictions)\n",
    "            confidence = float(predictions[0][emotion_idx])\n",
    "            \n",
    "            return self.EMOTIONS[emotion_idx], confidence\n",
    "        except Exception as e:\n",
    "            print(f\"Error prediciendo emoción: {str(e)}\")\n",
    "            return \"Error\", 0.0\n",
    "\n",
    "    def process_frame(self, frame: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Procesa un frame completo\"\"\"\n",
    "        faces = self.detect_faces(frame)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            try:\n",
    "                face_roi = frame[y:y+h, x:x+w]\n",
    "                if face_roi.size == 0:\n",
    "                    continue\n",
    "                \n",
    "                emotion, confidence = self.predict_emotion(face_roi)\n",
    "                \n",
    "                # Dibujar resultados\n",
    "                if confidence > 0.4:  # Umbral de confianza\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    cv2.rectangle(frame, (x, y-40), (x+w, y), (50, 50, 50), -1)\n",
    "                    text = f\"{emotion[:4]} {confidence*100:.0f}%\"\n",
    "                    cv2.putText(frame, text, (x+5, y-15), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                               cv2.LINE_AA)\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando rostro: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        return frame\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Bucle principal de ejecución\"\"\"\n",
    "        try:\n",
    "            print(\"Presiona 'Q' para salir...\")\n",
    "            last_time = time.time()\n",
    "            frame_count = 0\n",
    "            \n",
    "            while True:\n",
    "                # Capturar frame\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Error al capturar frame\")\n",
    "                    time.sleep(0.1)\n",
    "                    continue\n",
    "                \n",
    "                # Procesar frame\n",
    "                processed_frame = self.process_frame(frame)\n",
    "                \n",
    "                # Calcular y mostrar FPS\n",
    "                frame_count += 1\n",
    "                if frame_count % 10 == 0:\n",
    "                    fps = 10 / (time.time() - last_time)\n",
    "                    last_time = time.time()\n",
    "                    cv2.putText(processed_frame, f\"FPS: {fps:.1f}\", (10, 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                \n",
    "                # Mostrar resultado\n",
    "                cv2.imshow('Detección de Emociones', processed_frame)\n",
    "                \n",
    "                # Salir con 'Q'\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nPrograma interrumpido por el usuario\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error inesperado: {str(e)}\")\n",
    "        finally:\n",
    "            self._release_resources()\n",
    "\n",
    "    def _release_resources(self):\n",
    "        \"\"\"Libera los recursos correctamente\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, 'cap') and self.cap.isOpened():\n",
    "                self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Recursos liberados correctamente\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al liberar recursos: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Iniciando detector de emociones...\")\n",
    "    try:\n",
    "        detector = EmotionDetector()\n",
    "        detector.run()\n",
    "    except Exception as e:\n",
    "        print(f\"Error inicializando el detector: {str(e)}\")\n",
    "    finally:\n",
    "        print(\"Programa terminado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad2e6e-89b1-4cb4-9d82-6a9fbaa0e961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (2.19.0)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (0.10.21)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: jax in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.5.3)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.5.3)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: scipy>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "   ---------------------------------------- 0.0/39.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.9/39.4 MB 29.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 11.5/39.4 MB 31.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 18.1/39.4 MB 32.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 21.8/39.4 MB 28.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 25.4/39.4 MB 27.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 32.0/39.4 MB 26.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 37.2/39.4 MB 26.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.4/39.4 MB 25.8 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python-headless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Acceso denegado: 'C:\\\\Users\\\\ACER\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless tensorflow mediapipe numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4741ea-1061-439d-aeff-a141b380ca90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc860e6f-b977-4b96-b0b6-bca3aeabbb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
